DB_CONNECTION_STRING=postgresql://sy91dhb:...@178.156.142.230:5432/hd64m1ki

# Data fetching and splitting configuration
TOTAL_RECORDS_TO_FETCH=10000
TEST_SIZE=0.2
RANDOM_STATE=42
MINIMAL_FETCH_ONLY_TITLES=0

# Output files
TRAIN_FILE=./.data/hn_posts_train.parquet
TEST_FILE=./.data/hn_posts_test.parquet

# Parquet file path for Hacker News posts
HN_PARQUET_PATH=./.data/hn_posts_with_features.parquet

# Which split to process in data_processing.py ("train" or "test")
SPLIT=train

TRAIN_FILE=./.data/hn_posts_train.parquet
TEST_FILE=./.data/hn_posts_test.parquet
TITLES_FILE=./data/hn_posts_titles.parquet
PROCESSED_TRAIN_FILE=./.data/hn_posts_train_processed.parquet
PROCESSED_TEST_FILE=./.data/hn_posts_test_processed.parquet
VOCAB_PATH=./.data/vocabulary.json
DOMAIN_PARQUET_PATH=./.data/domain.parquet
MIN_DOMAIN_FREQ=50  # Minimum number of times a domain must appear to get its own ID; others mapped to <UNK_DOMAIN>
MAX_TITLE_TOKENS=80  # Maximum number of tokens for a title (for padding/truncation in model pipeline)

